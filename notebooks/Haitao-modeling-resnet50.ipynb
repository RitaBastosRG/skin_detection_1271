{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load Packages and init path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## load the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T12:34:39.737462Z",
     "start_time": "2023-06-20T12:34:33.184541Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-16T14:52:49.195588Z",
     "iopub.status.busy": "2023-06-16T14:52:49.194926Z",
     "iopub.status.idle": "2023-06-16T14:52:56.936508Z",
     "shell.execute_reply": "2023-06-16T14:52:56.935563Z",
     "shell.execute_reply.started": "2023-06-16T14:52:49.195551Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## set the work path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T12:34:53.268993Z",
     "start_time": "2023-06-20T12:34:53.265099Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "root_path='../'\n",
    "scenario_path='data/cat_8_binary'\n",
    "\n",
    "souce_path=root_path+'data/raw_data'\n",
    "target_path=root_path+scenario_path\n",
    "print(f'souce_path:{souce_path}')\n",
    "print(f'target_path:{target_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T12:34:58.142623Z",
     "start_time": "2023-06-20T12:34:57.628839Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-16T14:52:56.939094Z",
     "iopub.status.busy": "2023-06-16T14:52:56.938278Z",
     "iopub.status.idle": "2023-06-16T14:52:57.480394Z",
     "shell.execute_reply": "2023-06-16T14:52:57.479416Z",
     "shell.execute_reply.started": "2023-06-16T14:52:56.939059Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(f'{souce_path}/ISIC_2019_Training_GroundTruth.csv')\n",
    "display(data.head())\n",
    "print(f'the shape of the processed data setis {data.shape}')\n",
    "data.sum()[1:9].plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T12:02:04.621363Z",
     "start_time": "2023-06-20T12:02:04.602245Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-16T14:53:02.252461Z",
     "iopub.status.busy": "2023-06-16T14:53:02.251704Z",
     "iopub.status.idle": "2023-06-16T14:53:02.258020Z",
     "shell.execute_reply": "2023-06-16T14:53:02.256863Z",
     "shell.execute_reply.started": "2023-06-16T14:53:02.252430Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CATEGORIES = ['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC']\n",
    "\n",
    "categories=CATEGORIES\n",
    "data_by_cat={}\n",
    "for cat in categories:\n",
    "    data_by_cat[cat]=data[data[cat]>0]; \n",
    "    print(f'shape of data_by_cat[{cat}]: {data_by_cat[cat].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-16T15:49:14.462355Z",
     "start_time": "2023-06-16T15:49:14.456107Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Helper functions for image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T12:02:15.611362Z",
     "start_time": "2023-06-20T12:02:15.592151Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-16T14:53:27.665421Z",
     "iopub.status.busy": "2023-06-16T14:53:27.664701Z",
     "iopub.status.idle": "2023-06-16T14:53:27.679895Z",
     "shell.execute_reply": "2023-06-16T14:53:27.678952Z",
     "shell.execute_reply.started": "2023-06-16T14:53:27.665385Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def square_image(image: Image)->Image:\n",
    "    \"\"\"\n",
    "    crop image to sqare\n",
    "    \"\"\"\n",
    "    width, height = image.size\n",
    "    # Determine the size of the square crop\n",
    "    size = min(width, height)\n",
    "\n",
    "    # Calculate the crop coordinates\n",
    "    left = (width - size) // 2\n",
    "    top = (height - size) // 2\n",
    "    right = left + size\n",
    "    bottom = top + size\n",
    "\n",
    "    # Perform the crop\n",
    "    squared_image = image.crop((left, top, right, bottom))\n",
    "\n",
    "    return squared_image\n",
    "\n",
    "\n",
    "def detect_black_coners(image: Image)->int:\n",
    "    \"\"\"\n",
    "    return the radius of the circle if detected black coner, otherwise, return -1\n",
    "    This function needs to be improved for better accuracy if needed\n",
    "    Args:\n",
    "        image (Image): The image object which may have black corners.\n",
    "\n",
    "    Returns:\n",
    "        int: the radius of circle where is the the black corners from\n",
    "    \"\"\"\n",
    "    width, height=image.size\n",
    "    scope=min(width, height)//4 # the minimum radius to search for\n",
    "    step=3  # for better searching performance\n",
    "    margin=0.98\n",
    "\n",
    "    if width!=height:\n",
    "        image = square_image(image)\n",
    "\n",
    "    b_w_image = image.convert('L')\n",
    "    for i in range(1, scope, step):\n",
    "        left=i;right=width-i; top=i; bottom=height-i\n",
    "        color1=b_w_image.getpixel((top, left))\n",
    "        color2=b_w_image.getpixel((top, right))\n",
    "        color3=b_w_image.getpixel((bottom, left))\n",
    "        color4=b_w_image.getpixel((bottom, right))\n",
    "\n",
    "        if color1+color2+color3+color4>300:\n",
    "            break\n",
    "    if i>1:\n",
    "        radius = int((width//2-i)*np.sqrt(2)*margin)\n",
    "        # print(f'black corner detected, the radius is {radius}')\n",
    "        return radius\n",
    "\n",
    "    # print(f'No black corner detected')\n",
    "    return -1\n",
    "\n",
    "def remove_black_corners(image, radius) -> Image:\n",
    "    \"\"\"\n",
    "    This function remove the black corners of an image\n",
    "\n",
    "    Args:\n",
    "        image: The image object to which has black corners.\n",
    "        radius: the readius of the black corners\n",
    "\n",
    "    Returns:\n",
    "        image: image object which the black corners have been removed.\n",
    "    \"\"\"\n",
    "    width, height=image.size\n",
    "\n",
    "    new_width=int(radius*np.sqrt(2))\n",
    "    x = (width-new_width)//2\n",
    "    crop_area=(x, x, width-x, width-x)\n",
    "    image = image.crop(crop_area)\n",
    "\n",
    "    return image\n",
    "\n",
    "def process_and_save_image(source_file, target_file, argument=False):\n",
    "    # Load the image\n",
    "    image = Image.open(source_file)\n",
    "    # Square_Crop\n",
    "    image = square_image(image)\n",
    "\n",
    "    # Detect and remove corner edges\n",
    "    radius = detect_black_coners(image)\n",
    "    if radius> 0:\n",
    "        image=remove_black_corners(image, radius=radius)\n",
    "    # resize image\n",
    "    image = image.resize((400,400),resample=Image.BILINEAR)\n",
    "    \n",
    "    # export image file\n",
    "    image.save(f'{target_file}.jpg')\n",
    "    print(f'file {target_file} saved...')\n",
    "    \n",
    "    if argument:\n",
    "        for i in range(3):\n",
    "            image = image.rotate(90)\n",
    "            image.save(f'{target_file}_{i}.jpg')\n",
    "            print(f'file {target_file}_{i}.jpg saved...')\n",
    "        image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        print(f'file {target_file}_{i} saved...')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Helper function(s) for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T11:58:29.113673Z",
     "start_time": "2023-06-20T11:58:29.097853Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-16T14:31:20.121629Z",
     "iopub.status.busy": "2023-06-16T14:31:20.121162Z",
     "iopub.status.idle": "2023-06-16T14:31:20.133815Z",
     "shell.execute_reply": "2023-06-16T14:31:20.132628Z",
     "shell.execute_reply.started": "2023-06-16T14:31:20.121560Z"
    },
    "hidden": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_history(history, title='', axs=None, exp_name=\"\"):\n",
    "    f,(ax1,ax2,ax3,ax4) = plt.subplots(1, 4, figsize=(20, 4))\n",
    "    \n",
    "    ax1.plot(history.history['loss'], label='train loss')\n",
    "    ax1.plot(history.history['val_loss'], label='val loss')\n",
    "    ax1.set_title('Loss')\n",
    "    ax1.set_ylim(0.0, 100.0)\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='train accuracy')\n",
    "    ax2.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.axhline(y=0.9, color='green', linestyle='--')\n",
    "    ax2.set_ylim(0.5, 1.0)\n",
    "    ax2.legend()\n",
    "    \n",
    "    ax3.plot(history.history['recall'], label='train')\n",
    "    ax3.plot(history.history['val_recall'], label='val')\n",
    "    ax3.set_title('recall')\n",
    "    ax3.axhline(y=0.9, color='green', linestyle='--')\n",
    "    ax3.set_ylim(0.5, 1.0)\n",
    "    ax3.legend()\n",
    "\n",
    "    ax4.plot(history.history['f1_metric'], label='train f1_metric')\n",
    "    ax4.plot(history.history['val_f1_metric'], label='val f1_metric')\n",
    "    ax4.set_title('f1_metric')\n",
    "    ax4.axhline(y=0.9, color='green', linestyle='--')\n",
    "    ax4.set_ylim(0.5, 1.0)\n",
    "    ax4.legend()\n",
    "\n",
    "    return (ax1, ax2, ax3, ax4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T12:02:10.875483Z",
     "start_time": "2023-06-20T12:02:10.864355Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-16T14:53:15.554688Z",
     "iopub.status.busy": "2023-06-16T14:53:15.554336Z",
     "iopub.status.idle": "2023-06-16T14:53:15.564258Z",
     "shell.execute_reply": "2023-06-16T14:53:15.563314Z",
     "shell.execute_reply.started": "2023-06-16T14:53:15.554662Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_folder(folder_path):\n",
    "    import os\n",
    "    import shutil\n",
    "\n",
    "    # Check if the folder already exists\n",
    "    if os.path.exists(folder_path):\n",
    "        # Delete the existing folder\n",
    "        shutil.rmtree(folder_path)\n",
    "\n",
    "    # Create the folder\n",
    "    os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T12:08:12.974829Z",
     "start_time": "2023-06-20T12:04:25.668948Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-16T14:54:00.378854Z",
     "iopub.status.busy": "2023-06-16T14:54:00.378497Z",
     "iopub.status.idle": "2023-06-16T15:00:09.708935Z",
     "shell.execute_reply": "2023-06-16T15:00:09.707695Z",
     "shell.execute_reply.started": "2023-06-16T14:54:00.378824Z"
    },
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "# Please call this function only once you need re-prepare all the data\n",
    "##########################################################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def data_prep(categories=CATEGORIES, binary=True, n_max=1000, test_size=0.2, argument_if_needed=False):\n",
    "    # Create Folders\n",
    "    create_folder(target_path)\n",
    "    if binary:\n",
    "        create_folder(f'{target_path}/train')\n",
    "        create_folder(f'{target_path}/val')\n",
    "        create_folder(f'{target_path}/test')\n",
    "    else:\n",
    "        for cat in categories:\n",
    "            create_folder(f'{target_path}/train/{cat}')\n",
    "            create_folder(f'{target_path}/val/{cat}')\n",
    "            create_folder(f'{target_path}/test/{cat}')\n",
    "    \n",
    "    for cat in categories:\n",
    "        data_all=data_by_cat[cat]\n",
    "        argument_needed= data_by_cat[cat].shape[0]<n_max//4 and argument_if_needed\n",
    "        if data_by_cat[cat].shape[0]>n_max:\n",
    "            data_all=data_by_cat[cat].sample(n_max, random_state=42)\n",
    "\n",
    "        data_train, data_test = train_test_split(data_all, test_size=test_size)\n",
    "        data_train, data_val = train_test_split(data_train, test_size=test_size)\n",
    "        \n",
    "        for index, row in data_train.iterrows():\n",
    "            source_file = f\"{souce_path}/{cat}/{row['image']}.jpg\"\n",
    "            if binary:\n",
    "                target_file = f\"{target_path}/train/{row['image']}\"\n",
    "            else:\n",
    "                target_file = f\"{target_path}/train/{cat}/{row['image']}\"\n",
    "            process_and_save_image(source_file, target_file, argument_needed)\n",
    "        \n",
    "        print('======================================================')\n",
    "        \n",
    "        for index, row in data_val.iterrows():\n",
    "            source_file = f\"{souce_path}/{cat}/{row['image']}.jpg\"\n",
    "            if binary:\n",
    "                target_file = f\"{target_path}/val/{row['image']}\"\n",
    "            else:\n",
    "                target_file = f\"{target_path}/val/{cat}/{row['image']}\"\n",
    "            process_and_save_image(source_file, target_file, argument_needed)\n",
    "        \n",
    "        print('======================================================')\n",
    "        \n",
    "        for index, row in data_test.iterrows():\n",
    "            source_file = f\"{souce_path}/{cat}/{row['image']}.jpg\"\n",
    "            if binary:\n",
    "                target_file = f\"{target_path}/test/{row['image']}\"\n",
    "            else:\n",
    "                target_file = f\"{target_path}/test/{cat}/{row['image']}\"\n",
    "            process_and_save_image(source_file, target_file, False)\n",
    "    return\n",
    "\n",
    "data_prep(['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC'], \n",
    "           binary=False, \n",
    "           n_max=5000, \n",
    "           test_size=0.15, \n",
    "           argument_if_needed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## preprocess input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T12:24:12.100192Z",
     "start_time": "2023-06-20T12:24:12.088658Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-16T15:13:29.125061Z",
     "iopub.status.busy": "2023-06-16T15:13:29.124699Z",
     "iopub.status.idle": "2023-06-16T15:13:32.502940Z",
     "shell.execute_reply": "2023-06-16T15:13:32.502010Z",
     "shell.execute_reply.started": "2023-06-16T15:13:29.125032Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess_input_data(target_path, preprocess_input_method):\n",
    "    train_dir = target_path+'/train'\n",
    "    test_dir = target_path+'/test'\n",
    "    val_dir = target_path+'/val'\n",
    "\n",
    "    train_data = image_dataset_from_directory(\n",
    "        train_dir,\n",
    "        labels='inferred',\n",
    "        label_mode='categorical',\n",
    "        seed=123,\n",
    "        image_size=(400, 400),\n",
    "        batch_size=32)\n",
    "    train_data = train_data.map(lambda x, y: (preprocess_input_method(x), y))\n",
    "\n",
    "    val_data = image_dataset_from_directory(\n",
    "        val_dir,\n",
    "        labels='inferred',\n",
    "        label_mode='categorical',\n",
    "        seed=123,\n",
    "        image_size=(400, 400),\n",
    "        batch_size=32)\n",
    "    val_data = val_data.map(lambda x, y: (preprocess_input_method(x), y))\n",
    "\n",
    "    test_data = image_dataset_from_directory(\n",
    "        test_dir,\n",
    "        labels='inferred',\n",
    "        label_mode='categorical',\n",
    "        image_size=(400, 400),\n",
    "        batch_size=32)\n",
    "    test_data = test_data.map(lambda x, y: (preprocess_input_method(x), y))\n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T12:24:18.771217Z",
     "start_time": "2023-06-20T12:24:18.756693Z"
    },
    "execution": {
     "iopub.execute_input": "2023-06-16T15:15:14.461144Z",
     "iopub.status.busy": "2023-06-16T15:15:14.460158Z",
     "iopub.status.idle": "2023-06-16T15:15:14.470407Z",
     "shell.execute_reply": "2023-06-16T15:15:14.469084Z",
     "shell.execute_reply.started": "2023-06-16T15:15:14.461107Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "def load_model(pre_trained_model):\n",
    "    model = pre_trained_model(weights='imagenet', include_top=False, input_shape=(400,400,3))\n",
    "    return model\n",
    "\n",
    "def set_nontrainable_layers(model, n_layers=50):\n",
    "\n",
    "    model.trainable = False \n",
    "    return model\n",
    "\n",
    "def add_last_layers(model):\n",
    "    '''Take a pre-trained model, set its parameters as non-trainable, and add additional trainable layers on top'''\n",
    "    \n",
    "    model = models.Sequential(\n",
    "        [\n",
    "            layers.Input(shape=(400, 400, 3)),\n",
    "            layers.RandomZoom(0.25),\n",
    "            set_nontrainable_layers(model),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)),\n",
    "#             layers.Dropout(0.125),\n",
    "            layers.Dense(n_class, activation='softmax' if n_class > 2 else 'sigmoid')\n",
    "        ]\n",
    "    ) \n",
    "    return model\n",
    "\n",
    "def build_model(pre_trained_model, n_class=2):\n",
    "       \n",
    "    model = load_model(pre_trained_model)\n",
    "    model = add_last_layers(model)\n",
    "    \n",
    "    opt = optimizers.legacy.Adam(learning_rate=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy' if n_class>2 else 'binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy', 'Recall',f1_metric])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Instance model and input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T12:24:29.809093Z",
     "start_time": "2023-06-20T12:24:26.693794Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50, resnet50\n",
    "pre_processing_method = resnet50.preprocess_input\n",
    "pre_trained_model = ResNet50\n",
    "\n",
    "##############################\n",
    "path='../data/cat_7_binary'\n",
    "n_class=2\n",
    "##############################\n",
    "\n",
    "train_data, val_data, test_data = preprocess_input_data(\n",
    "    target_path = path, \n",
    "    preprocess_input_method = pre_processing_method\n",
    ")\n",
    "model = build_model(pre_trained_model, n_class)\n",
    "\n",
    "num_classes = train_data.element_spec[1].shape[1]\n",
    "num_batchs = len(train_data)\n",
    "\n",
    "scenario_name=f'{pre_trained_model.__name__}_{path}'\n",
    "print(scenario_name)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T07:46:46.490504Z",
     "start_time": "2023-06-20T06:37:32.303708Z"
    },
    "code_folding": [
     3,
     23,
     31,
     46,
     55
    ],
    "execution": {
     "iopub.execute_input": "2023-06-16T15:25:24.333077Z",
     "iopub.status.busy": "2023-06-16T15:25:24.332188Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "class MyModelCheckpoint(ModelCheckpoint):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.best_monitored_value = None\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Access the monitored metric value\n",
    "        monitored_value = logs[self.monitor]\n",
    "\n",
    "        # Check if the current value is better than the best value so far\n",
    "        if self.best_monitored_value is None or monitored_value > self.best_monitored_value:\n",
    "            self.best_monitored_value = monitored_value\n",
    "\n",
    "            # Modify the filename by appending the best monitored metric value\n",
    "            filepath = self.filepath.format(epoch=epoch, **logs)\n",
    "            filepath = filepath[:-3] + f'_{self.monitor}_{self.best_monitored_value:.4f}.h5'\n",
    "\n",
    "            # Save the model with the updated filepath\n",
    "            self.model.save(filepath, overwrite=True)\n",
    "        \n",
    "mcp = ModelCheckpoint(\n",
    "    f\"../models/{scenario_name}.h5\",\n",
    "    save_weights_only=False,\n",
    "    monitor='val_recall',\n",
    "    mode='max',\n",
    "    verbose=0,\n",
    "    save_best_only=True\n",
    ")\n",
    "lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    verbose=1,\n",
    "    min_lr=0\n",
    ")\n",
    "es = EarlyStopping(\n",
    "    monitor = 'val_accuracy', \n",
    "    mode = 'max', \n",
    "    patience = 10, \n",
    "    verbose = 1, \n",
    "    restore_best_weights = True\n",
    ")\n",
    "num_epochs = 100\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=num_epochs,\n",
    "    callbacks=[es, lr, mcp],\n",
    "    validation_data=val_data,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "end_time = timeit.default_timer()\n",
    "execution_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-20T07:51:27.206977Z",
     "start_time": "2023-06-20T07:51:03.208772Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f'scenario: {scenario_name}_{path}, training time(min):{execution_time//60}')\n",
    "print(\"\"\"\n",
    "layers.RandomZoom(0.5)\n",
    "dense_layer = layers.Dense(128, activation='relu')\n",
    "opt = optimizers.legacy.Adam(learning_rate=1e-6)\n",
    "\"\"\")\n",
    "model.evaluate(test_data)\n",
    "plot_history(history);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "287px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
